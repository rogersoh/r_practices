---
title: "Lecture Code"
author: "Rochelle Terman"
date: "2021"
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

## Scraping Presidential Statements

To demonstrate webscraping in R, we're going to collect records on presidential statements here: https://www.presidency.ucsb.edu/

Let's say we're interested in how presidents speak about "space exploration". On the website, we punch in this search term, and we get the [following 346 results](https://www.presidency.ucsb.edu/advanced-search?field-keywords=%22space+exploration%22&field-keywords2=&field-keywords3=&from%5Bdate%5D=&to%5Bdate%5D=&person2=&items_per_page=100). 

Our goal is to scrape these records, and store pertinent information in a dataframe. We will be doing this in two steps:

1. Write a function to scrape each individual record page (these notes).
2. Use this function to loop through all results, and collect all pages (homework).

Load the following packages to get started:

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(rvest)
library(stringr)
library(purrr)
library(knitr)
library(lubridate)
```

### Using `RVest` to Read HTML

The package `RVest` allows us to:

1. Collect the HTML source code of a webpage
2. Read the HTML of the page
3. Select and keep certain elements of the page that are of interest

Let's start with step one. We use the `read_html` function to call the results URL and grab the HTML response. Store this result as an object.

```{r}
document1 <- read_html("https://www.bible.com/bible/111/1CH.1.NIV")

#Let's take a look at the object we just created
document1

```
This is pretty messy. We need to use `RVest` to make this information more usable.

### Find Page Elements

`RVest` has a number of functions to find information on a page. Like other webscraping tools, RVest lets you find elements by their:

1. HTML tags
2. HTML Attributes
3. CSS Selectors

Let's search first for HTML tags.

The function `html_nodes` searches a parsed HTML object to find all the elements with a particular HTML tag, and returns all of those elements.

What does the example below do?

```{r}
html_nodes(document1, "a")
```


Using selector gadget, we found out that the CSS selector for document's speaker is `.diet-title a`.

We can then modify our argument in `html_nodes` to look for this more specific CSS selector. 

```{r}
html_nodes(document1, ".verse span") 
```

### Get Attributes and Text of Elements

Once we identify elements, we want to access information in that element. Oftentimes this means two things:

1) Text
2) Attributes

Getting the text inside an element is pretty straightforward. We can use the `html_text()` command  inside of `RVest` to get the text of an element:

```{r}
html_nodes(document1, ".verse span") %>%
  html_text() #select text of element

```

4. Text

```{r, message=FALSE}
#Text
book_chapter <- html_nodes(document1, "h1") %>%
  html_text()


html_nodes(document1, ".verse span") %>%
  html_text() %>%
  str_replace("(^\\d+)", "@\\1&") %>%
  str_replace("@(\\d+)&:", "\\1:")


#this is a long document, so let's just display the first 1000 characters
text %>% substr(1, 1000) 
```

```{r}
fruits <- c("1 Adam, Seth, Enosh,  2 Kenan, Mahalalel, Jared,  36 Enoch, Methuselah, Lamech, Noah.    4 The sons of Noah: #1:4 Septuagint; Hebrew does not have this line. # 1:4 Septuagint; Hebrew does not have this line. 1:4  Septuagint; Hebrew does not have this line. 5 Shem, Ham and Japheth. ")
str_view_all(fruits, "\\s(?=(\\d+ ))")
text <- str_replace_all(fruits, "\\s(?=(\\d ))", "@") %>%
  str_split("@") 

text

str_view(text, " ")

str_replace(fruits, "\\s", "#")

str_view_all(fruits, "(?<=(\\d+ ))")
str_view_all(fruits, "\\d+")


(?<=\\d+) 
str_replace_all(fruits, "$`([0-9]+)", "\\`@")

str_replace_all(fruits, "[aeiou]", toupper)
str_replace_all(fruits, "b", NA_character_)

str_replace(fruits, "([aeiou])", "")
str_replace(fruits, "([aeiou])", "\\1\\2")
str_replace(fruits, "[aeiou]", c("1", "2", "3"))
str_replace(fruits, c("a", "e", "i"), "-")
```


### Challenge 1: Make a function

Make a function called `scrape_docs` that accepts a URL of an individual document, scrapes the page, and returns a list containing the document's date, speaker, title, and full text.

This involves:

- Requesting the HTML of the webpage using the full URL and RVest.
- Using RVest to locate all elements on the page we want to save.
- Storing each of these items into a list.
- Returning this list.

```{r eval = F}
scrape_docs <- function(URL){

  # YOUR CODE HERE
  
}

# uncomment to test
# scrape_doc("https://www.presidency.ucsb.edu/documents/letter-t-keith-glennan-administrator-national-aeronautics-and-space-administration")
```
