---
title: "Biblica Bible webscraping"
author: "Roger Soh"
date: "2021"
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

## Scraping Biblica Bible

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(rvest)
library(stringr)
library(purrr)
library(knitr)
library(lubridate)
```

Biblica.com 

```{r}
bibletext <- data.frame(matrix(ncol= 4, nrow =0))
colnames(bibletext) <- c("book","chapter", "verse", "text")

bibletext <- read.csv("./data/bible/bibletext.csv") %>%
  select(-1)
```



```{r scraping}
url <- c("https://www.biblica.com/bible/niv/exodus/41/")

biblica_webscrap <- read_html(url)

book_chapter <- html_nodes(biblica_webscrap, "h1") %>%
  html_text() %>% #select text of element
  str_replace("\\s[:punct:]\\sNew International Version \\(NIV\\)" , "")

book_chapter

verse_text <- html_nodes(biblica_webscrap, ".verse-span") %>%
  html_text() %>%
  str_replace("(^\\d+)", "@\\1&") %>%
  str_flatten(collapse = " ") %>%
  str_split("@")

book_verse <- data.frame(book_chapter, verse_text) %>%
  as_tibble()

colnames(book_verse) <- c("book_chap", "verse_text")

book_verse <- book_verse %>%
  filter(verse_text != "")

tmp_bibletext <- book_verse %>%
  separate(book_chap, c("book", "chapter")) %>%
  separate(verse_text, c("verse", "text"), "& ")

bibletext <- rbind(bibletext, tmp_bibletext)

bibletext %>%
  tail(2)
```

```{r save csv}
write.csv(bibletext, "./data/bible/bibletext.csv")


```


```{r}
# Extract by name or position
# .default specifies value for elements that are missing or NULL
l1 <- list(list(a = 1L), list(a = NULL, b = 2L), list(b = 3L))
l1 %>% map("a", .default = "???")
l1 %>% map_int("b", .default = NA)
l1 %>% map_int(2, .default = NA)
```







### Challenge 1: Make a function

Make a function called `scrape_docs` that accepts a URL of an individual document, scrapes the page, and returns a list containing the document's date, speaker, title, and full text.

This involves:

- Requesting the HTML of the webpage using the full URL and RVest.
- Using RVest to locate all elements on the page we want to save.
- Storing each of these items into a list.
- Returning this list.

```{r eval = F}
scrape_docs <- function(URL) {

  biblica_webscrap <- read_html(URL)
  
  book_chapter <- html_nodes(biblica_webscrap, "h1") %>%
    html_text() %>% #select text of element
    str_replace("\\s[:punct:]\\sNew International Version \\(NIV\\)" , "")
  
  book_chapter
  
  verse_text <- html_nodes(biblica_webscrap, ".verse-span") %>%
    html_text() %>%
    str_replace("(^\\d+)", "@\\1&") %>%
    str_flatten(collapse = " ") %>%
    str_split("@")
  
  book_verse <- data.frame(book_chapter, verse_text) %>%
    as_tibble()
  
  colnames(book_verse) <- c("book_chap", "verse_text")
  
  book_verse <- book_verse %>%
    filter(verse_text != "")
  
  tmp_bibletext <- book_verse %>%
    separate(book_chap, c("book", "chapter")) %>%
    separate(verse_text, c("verse", "text"), "& ")
  
  bibletext <- rbind(bibletext, tmp_bibletext)
  
  bibletext %>%
    tail(2)
  
}


# uncomment to test
scrape_docs(
  "https://www.biblica.com/bible/niv/leviticus/1/"
)
```
